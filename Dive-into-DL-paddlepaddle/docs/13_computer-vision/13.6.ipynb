{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.6. 目标检测数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**目标检测领域没有像MNIST和Fashion-MNIST那样的小数据集。 为了快速测试目标检测模型，我们收集并标记了一个小型数据集。 首先，我们拍摄了一组香蕉的照片，并生成了1000张不同角度和大小的香蕉图像。 然后，我们在一些背景图片的随机位置上放一张香蕉的图像。 最后，我们在图片上为这些香蕉标记了边界框。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.6.1. 下载数据集\n",
    "\n",
    "**包含所有图像和CSV标签文件的香蕉检测数据集可以直接从互联网下载。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T12:12:58.880954Z",
     "iopub.status.busy": "2022-02-09T12:12:58.880026Z",
     "iopub.status.idle": "2022-02-09T12:12:58.888995Z",
     "shell.execute_reply": "2022-02-09T12:12:58.888382Z",
     "shell.execute_reply.started": "2022-02-09T12:12:58.880915Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import paddle\r\n",
    "from paddle.vision import image_load\r\n",
    "from d2l import paddle as d2l\r\n",
    "\r\n",
    "#@save\r\n",
    "d2l.DATA_HUB['banana-detection'] = (\r\n",
    "    d2l.DATA_URL + 'banana-detection.zip',\r\n",
    "    '5de26c8fce5ccdea9f91267273464dc968d20d72')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据集\n",
    "\n",
    "**通过read_data_bananas函数，我们读取香蕉检测数据集。 该数据集包括一个的CSV文件，内含目标类别标签和位于左上角和右下角的真实边界框坐标。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T12:13:16.928400Z",
     "iopub.status.busy": "2022-02-09T12:13:16.927414Z",
     "iopub.status.idle": "2022-02-09T12:13:16.934309Z",
     "shell.execute_reply": "2022-02-09T12:13:16.933563Z",
     "shell.execute_reply.started": "2022-02-09T12:13:16.928348Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@save\r\n",
    "def read_data_bananas(is_train=True):\r\n",
    "    \"\"\"读取香蕉检测数据集中的图像和标签\"\"\"\r\n",
    "    data_dir = d2l.download_extract('banana-detection')\r\n",
    "    csv_fname = os.path.join(data_dir, 'bananas_train' if is_train\r\n",
    "                             else 'bananas_val', 'label.csv')\r\n",
    "    csv_data = pd.read_csv(csv_fname)\r\n",
    "    csv_data = csv_data.set_index('img_name')\r\n",
    "    images, targets = [], []\r\n",
    "    for img_name, target in csv_data.iterrows():\r\n",
    "        images.append(image_load(\r\n",
    "            os.path.join(data_dir, 'bananas_train' if is_train else\r\n",
    "                         'bananas_val', 'images', f'{img_name}')))\r\n",
    "        # 这里的target包含（类别，左上角x，左上角y，右下角x，右下角y），\r\n",
    "        # 其中所有图像都具有相同的香蕉类（索引为0）\r\n",
    "        targets.append(list(target))\r\n",
    "    return images, torch.tensor(targets).unsqueeze(1) / 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**通过使用read_data_bananas函数读取图像和标签，以下BananasDataset类别将允许我们创建一个自定义Dataset实例来加载香蕉检测数据集。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T12:16:15.805760Z",
     "iopub.status.busy": "2022-02-09T12:16:15.804960Z",
     "iopub.status.idle": "2022-02-09T12:16:15.811297Z",
     "shell.execute_reply": "2022-02-09T12:16:15.810657Z",
     "shell.execute_reply.started": "2022-02-09T12:16:15.805686Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@save\r\n",
    "from paddle.io import Dataset,DataLoader\r\n",
    "class BananasDataset(Dataset):\r\n",
    "    \"\"\"一个用于加载香蕉检测数据集的自定义数据集\"\"\"\r\n",
    "    def __init__(self, is_train):\r\n",
    "        self.features, self.labels = read_data_bananas(is_train)\r\n",
    "        print('read ' + str(len(self.features)) + (f' training examples' if\r\n",
    "              is_train else f' validation examples'))\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        return (self.features[idx].float(), self.labels[idx])\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**最后，我们定义load_data_bananas函数，来为训练集和测试集返回两个数据加载器实例。对于测试集，无须按随机顺序读取它。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T12:16:35.097335Z",
     "iopub.status.busy": "2022-02-09T12:16:35.096411Z",
     "iopub.status.idle": "2022-02-09T12:16:35.101167Z",
     "shell.execute_reply": "2022-02-09T12:16:35.100603Z",
     "shell.execute_reply.started": "2022-02-09T12:16:35.097295Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@save\r\n",
    "def load_data_bananas(batch_size):\r\n",
    "    \"\"\"加载香蕉检测数据集\"\"\"\r\n",
    "    train_iter = DataLoader(BananasDataset(is_train=True),\r\n",
    "                                             batch_size, shuffle=True)\r\n",
    "    val_iter = DataLoader(BananasDataset(is_train=False),\r\n",
    "                                           batch_size)\r\n",
    "    return train_iter, val_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**让我们读取一个小批量，并打印其中的图像和标签的形状。 图像的小批量的形状为（批量大小、通道数、高度、宽度），看起来很眼熟：它与我们之前图像分类任务中的相同。 标签的小批量的形状为（批量大小， m ，5），其中 m 是数据集的任何图像中边界框可能出现的最大数量。**\n",
    "\n",
    "**小批量计算虽然高效，但它要求每张图像含有相同数量的边界框，以便放在同一个批量中。 通常来说，图像可能拥有不同数量个边界框；因此，在达到 m 之前，边界框少于 m 的图像将被非法边界框填充。 这样，每个边界框的标签将被长度为5的数组表示。 数组中的第一个元素是边界框中对象的类别，其中-1表示用于填充的非法边界框。 数组的其余四个元素是边界框左上角和右下角的（ x ， y ）坐标值（值域在0到1之间）。 对于香蕉数据集而言，由于每张图像上只有一个边界框，因此 m=1 。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T12:16:49.000502Z",
     "iopub.status.busy": "2022-02-09T12:16:48.999560Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从http://d2l-data.s3-accelerate.amazonaws.com/banana-detection.zip下载./data/banana-detection.zip...\n"
     ]
    }
   ],
   "source": [
    "batch_size, edge_size = 32, 256\r\n",
    "train_iter, _ = load_data_bananas(batch_size)\r\n",
    "batch = next(iter(train_iter))\r\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.6.3. 演示\n",
    "\n",
    "**让我们展示10幅带有真实边界框的图像。 我们可以看到在所有这些图像中香蕉的旋转角度、大小和位置都有所不同。 当然，这只是一个简单的人工数据集，实践中真实世界的数据集通常要复杂得多。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = (batch[0][0:10].permute(0, 2, 3, 1)) / 255\r\n",
    "axes = d2l.show_images(imgs, 2, 5, scale=2)\r\n",
    "for ax, label in zip(axes, batch[1][0:10]):\r\n",
    "    d2l.show_bboxes(ax, [label[0][1:5] * edge_size], colors=['w'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.6.4 小结\n",
    "\n",
    "**· 我们收集的香蕉检测数据集可用于演示目标检测模型。**\n",
    "\n",
    "**· 用于目标检测的数据加载与图像分类的数据加载类似。但是，在目标检测中，标签还包含真实边界框的信息，它不出现在图像分类中。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.6.5 练习\n",
    "\n",
    "**1.在香蕉检测数据集中演示其他带有真实边界框的图像。它们在边界框和目标方面有什么不同？**\n",
    "\n",
    "**2.假设我们想要将数据增强（例如随机裁剪）应用于目标检测。它与图像分类中的有什么不同？提示：如果裁剪的图像只包含物体的一小部分会怎样？**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
